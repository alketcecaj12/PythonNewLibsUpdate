{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e87a53d-0b07-4986-96be-1877193203ec",
   "metadata": {},
   "source": [
    "### Dask\n",
    "\n",
    "- A flexible library for parallel computing in Python, designed to scale up computations for handling large datasets. It works well with existing Python libraries like NumPy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef126d45-0b95-4f64-bc96-f732b0fb9ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.881853\n",
      "1    0.969647\n",
      "2    1.161214\n",
      "3    0.617403\n",
      "4    0.818888\n",
      "dtype: float64\n",
      "          Numeric_0     Numeric_1     Numeric_2     Numeric_3     Numeric_4  \\\n",
      "count  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06   \n",
      "mean   5.003345e-01  4.994787e-01  5.001205e-01  5.000972e-01  4.999022e-01   \n",
      "std    2.885911e-01  2.885151e-01  2.887497e-01  2.887905e-01  2.886225e-01   \n",
      "min    5.188446e-07  3.774576e-07  9.958058e-07  3.907137e-07  3.869667e-07   \n",
      "25%    2.505941e-01  2.505341e-01  2.506572e-01  2.504032e-01  2.508170e-01   \n",
      "50%    5.012175e-01  4.998475e-01  5.016284e-01  5.006099e-01  5.003154e-01   \n",
      "75%    7.508154e-01  7.495893e-01  7.504384e-01  7.507173e-01  7.500634e-01   \n",
      "max    9.999983e-01  9.999994e-01  9.999979e-01  9.999999e-01  9.999966e-01   \n",
      "\n",
      "          Numeric_5     Numeric_6     Numeric_7     Numeric_8     Numeric_9  \n",
      "count  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06  \n",
      "mean   4.999513e-01  4.998491e-01  4.998747e-01  5.004690e-01  4.998475e-01  \n",
      "std    2.886320e-01  2.888112e-01  2.885727e-01  2.888237e-01  2.886401e-01  \n",
      "min    7.243191e-07  3.371209e-07  4.679125e-07  8.838978e-07  3.832283e-07  \n",
      "25%    2.502138e-01  2.505511e-01  2.500573e-01  2.507157e-01  2.505733e-01  \n",
      "50%    5.010810e-01  5.000885e-01  5.000068e-01  5.014255e-01  5.003940e-01  \n",
      "75%    7.496423e-01  7.513007e-01  7.503454e-01  7.507311e-01  7.500705e-01  \n",
      "max    9.999999e-01  9.999992e-01  9.999997e-01  9.999998e-01  9.999995e-01  \n",
      "Categorical_3\n",
      "S    200338\n",
      "Q    200277\n",
      "P    199910\n",
      "R    199812\n",
      "T    199663\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate a large dataset (as before)\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Numeric_0': np.random.rand(1000000),\n",
    "    'Numeric_1': np.random.rand(1000000),\n",
    "    'Numeric_2': np.random.rand(1000000),\n",
    "    'Numeric_3': np.random.rand(1000000),\n",
    "    'Numeric_4': np.random.rand(1000000),\n",
    "    'Numeric_5': np.random.rand(1000000),\n",
    "    'Numeric_6': np.random.rand(1000000),\n",
    "    'Numeric_7': np.random.rand(1000000),\n",
    "    'Numeric_8': np.random.rand(1000000),\n",
    "    'Numeric_9': np.random.rand(1000000),\n",
    "    'Categorical_3': np.random.choice(['P', 'Q', 'R', 'S', 'T'], size=1000000)\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "pdf = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "pdf.to_csv('large_dataset.csv', index=False)\n",
    "\n",
    "# Now use Dask to read the CSV file\n",
    "df = dd.read_csv('large_dataset.csv')\n",
    "\n",
    "# Perform computations\n",
    "result = (df['Numeric_0'] + df['Numeric_9'] * df['Numeric_3'])\n",
    "\n",
    "# Display the first few results\n",
    "print(result.compute().head())\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary = df.describe().compute()\n",
    "print(summary)\n",
    "\n",
    "# Count value occurrences in a categorical column\n",
    "value_counts = df['Categorical_3'].value_counts().compute()\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a36ed1-4922-4d00-af18-7589844df420",
   "metadata": {},
   "source": [
    "## Step by step \n",
    "\n",
    "\n",
    "- Reading large CSV files efficiently using dd.read_csv().\n",
    "\n",
    "- Performing element-wise operations on columns.\n",
    "\n",
    "- Using compute() to execute lazy operations and retrieve results.\n",
    "\n",
    "- Calculating summary statistics with describe().\n",
    "\n",
    "- Counting value occurrences in categorical columns.\n",
    "Dask allows for these operations to be performed on datasets that may not fit into memory, by breaking them into smaller chunks and processing them in parallel. This makes it possible to work with large datasets on a single machine or across a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445a039-5305-4754-9e38-1f6b0585ae80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd328cdc-5f2c-484a-8e46-15dd299a48ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c8819-c2f4-4bf9-b647-7c1f01a48e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f24923-cec9-4634-a330-97fd60249c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a85a4-435c-45fc-9ed9-d1d60a4f6289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a23490-a3b8-4396-b27f-74529a5ea26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280dac6-2ce8-4a14-ab8f-ecb8e076d346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
